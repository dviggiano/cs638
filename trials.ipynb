{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd255e42ddc0860"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:25:33.622518Z",
     "start_time": "2024-04-24T19:25:33.241980Z"
    }
   },
   "outputs": [],
   "source": [
    "import dotenv, os, openai, csv\n",
    "\n",
    "EXAMPLES_DIR = 'examples'\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "llm = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def ask_llm(prompt: str) -> str:\n",
    "    response = llm.chat.completions.create(\n",
    "        model='gpt-3.5',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    output = response.choices[0].message.content.strip()\n",
    "    return output\n",
    "\n",
    "examples_by_task_class = {}\n",
    "\n",
    "# load examples from CSVs\n",
    "# data is formatted as follows:\n",
    "#   q_1,a_1\n",
    "#   q2,a_2\n",
    "#   ...\n",
    "#   q_n,a_n\n",
    "\n",
    "for filename in os.listdir(EXAMPLES_DIR):\n",
    "    if filename.endswith('.csv'):\n",
    "        path = os.path.join(EXAMPLES_DIR, file)\n",
    "        \n",
    "        with open(path, newline='', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            task_class = filename[:-4]\n",
    "            examples_by_task_class[task_class] = [{'q': row[0], 'a': row[1]} for row in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ecfd9896481419"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for task_class, examples in examples_by_task_class.items():\n",
    "    # case 1: use n / 2 examples\n",
    "        # case 1a: use the first n / 2 examples\n",
    "        # case 1b: use the other n / 2 examples\n",
    "    # case 2: use all n examples\n",
    "    # case 3: use n / 2 examples, duplicated (for n total examples)\n",
    "        # case 3a: use the first n / 2 examples\n",
    "        # case 3b: use the other n / 2 examples\n",
    "    \n",
    "    # prompt GPT in each case, accumulate responses and save to output file for each task_class\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95e4fc3a15872072"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
